{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r'C:\\Users\\PIYUSH\\Downloads\\merged_training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotions\n",
       "27383   i feel awful about it too because it s my job ...  sadness\n",
       "110083                              im alone i feel awful  sadness\n",
       "140764  ive probably mentioned this before but i reall...      joy\n",
       "100071           i was feeling a little low few days back  sadness\n",
       "2837    i beleive that i am much more sensitive to oth...     love"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.iloc[:80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['content', 'sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiments'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making all letters lowercase\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "#Removing Punctuation, Symbols\n",
    "data['content'] = data['content'].str.replace('[^\\w\\s]',' ')\n",
    "#Removing Stop Words using NLTK\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "#Lemmatisation\n",
    "from textblob import Word\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to find the top 10,000 rarest words appearing in the data\n",
    "# freq = pd.Series(' '.join(data['content']).split()).value_counts()[-10000:]\n",
    "# # Removing all those rarely appearing words from the data\n",
    "# freq = list(freq.index)\n",
    "# data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>feel awful job get position succeed happen</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned really feel proud actua...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>feeling little low day back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>beleive much sensitive people feeling tend com...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content sentiments\n",
       "27383          feel awful job get position succeed happen    sadness\n",
       "110083                                im alone feel awful    sadness\n",
       "140764  ive probably mentioned really feel proud actua...        joy\n",
       "100071                        feeling little low day back    sadness\n",
       "2837    beleive much sensitive people feeling tend com...       love"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0\n",
    "for i in range(data.shape[0]):\n",
    "    l=max(len(data.iloc[i]['content'].split(' ')),l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enthusiasm=happy=fun\n",
    "empty=neutral\n",
    "boredom=sadness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>feel awful job get position succeed happen</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned really feel proud actua...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>feeling little low day back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>beleive much sensitive people feeling tend com...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content sentiments\n",
       "27383          feel awful job get position succeed happen    sadness\n",
       "110083                                im alone feel awful    sadness\n",
       "140764  ive probably mentioned really feel proud actua...        joy\n",
       "100071                        feeling little low day back    sadness\n",
       "2837    beleive much sensitive people feeling tend com...       love"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding output labels 'sadness' as '1' & 'happiness' as '0'\n",
    "from sklearn import preprocessing\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.sentiments.values)\n",
    "# Splitting into training and testing data in 90:10 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, ..., 2, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, test_size=0.1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting TF-IDF parameters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf=X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tfidf=X_val_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tfidf=X_val_tfidf.reshape(X_val_tfidf.shape[0],1,X_val_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf=X_train_tfidf.reshape(X_train_tfidf.shape[0],1,X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 6)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_label=to_categorical(y_train)\n",
    "val_label=to_categorical(y_val)\n",
    "y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1, 256)            1287168   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1542      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,814,022\n",
      "Trainable params: 1,814,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(LSTM(256,input_shape=(1,1000),return_sequences=True))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(LSTM(256))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(6))\n",
    "classifier.add(Activation('softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list=[X_val_tfidf,val_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile( loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64800 samples, validate on 7200 samples\n",
      "Epoch 1/20\n",
      "64800/64800 [==============================] - 22s 342us/sample - loss: 0.2656 - accuracy: 0.8904 - val_loss: 0.2481 - val_accuracy: 0.8957\n",
      "Epoch 2/20\n",
      "64800/64800 [==============================] - 21s 324us/sample - loss: 0.2598 - accuracy: 0.8910 - val_loss: 0.2587 - val_accuracy: 0.8900\n",
      "Epoch 3/20\n",
      "64800/64800 [==============================] - 20s 316us/sample - loss: 0.2521 - accuracy: 0.8953 - val_loss: 0.2688 - val_accuracy: 0.8854\n",
      "Epoch 4/20\n",
      "64800/64800 [==============================] - 20s 316us/sample - loss: 0.2485 - accuracy: 0.8959 - val_loss: 0.2738 - val_accuracy: 0.8858\n",
      "Epoch 5/20\n",
      "64800/64800 [==============================] - 22s 332us/sample - loss: 0.2402 - accuracy: 0.8995 - val_loss: 0.2786 - val_accuracy: 0.8839\n",
      "Epoch 6/20\n",
      "64800/64800 [==============================] - 21s 324us/sample - loss: 0.2371 - accuracy: 0.9004 - val_loss: 0.2834 - val_accuracy: 0.8839\n",
      "Epoch 7/20\n",
      "64800/64800 [==============================] - 24s 366us/sample - loss: 0.2292 - accuracy: 0.9046 - val_loss: 0.2841 - val_accuracy: 0.8811\n",
      "Epoch 8/20\n",
      "64800/64800 [==============================] - 23s 349us/sample - loss: 0.2225 - accuracy: 0.9062 - val_loss: 0.2920 - val_accuracy: 0.8789\n",
      "Epoch 9/20\n",
      "64800/64800 [==============================] - 23s 360us/sample - loss: 0.2178 - accuracy: 0.9079 - val_loss: 0.2906 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "64800/64800 [==============================] - 22s 346us/sample - loss: 0.2122 - accuracy: 0.9108 - val_loss: 0.2958 - val_accuracy: 0.8792\n",
      "Epoch 11/20\n",
      "64800/64800 [==============================] - 23s 351us/sample - loss: 0.2068 - accuracy: 0.9131 - val_loss: 0.3005 - val_accuracy: 0.8796\n",
      "Epoch 12/20\n",
      "64800/64800 [==============================] - 24s 369us/sample - loss: 0.2024 - accuracy: 0.9146 - val_loss: 0.3040 - val_accuracy: 0.8785\n",
      "Epoch 13/20\n",
      "64800/64800 [==============================] - 24s 370us/sample - loss: 0.1936 - accuracy: 0.9171 - val_loss: 0.3132 - val_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "64800/64800 [==============================] - 23s 357us/sample - loss: 0.1897 - accuracy: 0.9201 - val_loss: 0.3156 - val_accuracy: 0.8789\n",
      "Epoch 15/20\n",
      "64800/64800 [==============================] - 22s 344us/sample - loss: 0.1825 - accuracy: 0.9227 - val_loss: 0.3224 - val_accuracy: 0.8764\n",
      "Epoch 16/20\n",
      "64800/64800 [==============================] - 22s 338us/sample - loss: 0.1799 - accuracy: 0.9235 - val_loss: 0.3245 - val_accuracy: 0.8768\n",
      "Epoch 17/20\n",
      "64800/64800 [==============================] - 22s 340us/sample - loss: 0.1740 - accuracy: 0.9260 - val_loss: 0.3335 - val_accuracy: 0.8786\n",
      "Epoch 18/20\n",
      "64800/64800 [==============================] - 22s 336us/sample - loss: 0.1705 - accuracy: 0.9277 - val_loss: 0.3322 - val_accuracy: 0.8810\n",
      "Epoch 19/20\n",
      "64800/64800 [==============================] - 22s 341us/sample - loss: 0.1665 - accuracy: 0.9299 - val_loss: 0.3356 - val_accuracy: 0.8792\n",
      "Epoch 20/20\n",
      "64800/64800 [==============================] - 24s 364us/sample - loss: 0.1582 - accuracy: 0.9336 - val_loss: 0.3490 - val_accuracy: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x290ca138be0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_tfidf,y_label,batch_size=120,epochs=20,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = classifier.predict(X_val_tfidf) \n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 2, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_val,y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = {}\n",
    "with open(r'G:\\data\\glove.6B.100d.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:],dtype='float32')\n",
    "        \n",
    "        #print(word)\n",
    "        #print(coeffs)\n",
    "        embeddings[word] = coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['the'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputEmbeddings(X):\n",
    "    embedding_matrix_output = np.zeros((X.shape[0],l,100))\n",
    "    for ix in range(X.shape[0]):\n",
    "        sent = X['content'].iloc[ix].split()\n",
    "        for jx in range(len(sent)):\n",
    "            try:\n",
    "                embedding_matrix_output[ix][jx] = embeddings[sent[jx].lower()]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    return embedding_matrix_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feel awful job get position succeed happen'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_data=getOutputEmbeddings(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 45, 100)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(glove_data, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 6)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_label=to_categorical(y_train)\n",
    "val_label=to_categorical(y_val)\n",
    "y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 45, 100)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 45, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 45, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 774       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 249,606\n",
      "Trainable params: 249,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(LSTM(128,input_shape=(45,100),return_sequences=True))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(LSTM(128))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(6))\n",
    "classifier.add(Activation('softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile( loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64800 samples, validate on 7200 samples\n",
      "Epoch 1/20\n",
      "64800/64800 [==============================] - 182s 3ms/sample - loss: 1.1351 - accuracy: 0.5701 - val_loss: 0.7749 - val_accuracy: 0.7147\n",
      "Epoch 2/20\n",
      "64800/64800 [==============================] - 173s 3ms/sample - loss: 0.5057 - accuracy: 0.8183 - val_loss: 0.3647 - val_accuracy: 0.8792\n",
      "Epoch 3/20\n",
      "64800/64800 [==============================] - 175s 3ms/sample - loss: 0.2675 - accuracy: 0.9018 - val_loss: 0.2366 - val_accuracy: 0.9101\n",
      "Epoch 4/20\n",
      "64800/64800 [==============================] - 177s 3ms/sample - loss: 0.1977 - accuracy: 0.9187 - val_loss: 0.1946 - val_accuracy: 0.9167\n",
      "Epoch 5/20\n",
      "64800/64800 [==============================] - 182s 3ms/sample - loss: 0.1648 - accuracy: 0.9257 - val_loss: 0.1757 - val_accuracy: 0.9242\n",
      "Epoch 6/20\n",
      "64800/64800 [==============================] - 176s 3ms/sample - loss: 0.1446 - accuracy: 0.9302 - val_loss: 0.1690 - val_accuracy: 0.9257\n",
      "Epoch 7/20\n",
      "64800/64800 [==============================] - 185s 3ms/sample - loss: 0.1316 - accuracy: 0.9339 - val_loss: 0.1554 - val_accuracy: 0.9192\n",
      "Epoch 8/20\n",
      "64800/64800 [==============================] - 178s 3ms/sample - loss: 0.1234 - accuracy: 0.9347 - val_loss: 0.1544 - val_accuracy: 0.9253\n",
      "Epoch 9/20\n",
      "64800/64800 [==============================] - 188s 3ms/sample - loss: 0.1194 - accuracy: 0.9369 - val_loss: 0.1436 - val_accuracy: 0.9299\n",
      "Epoch 10/20\n",
      "64800/64800 [==============================] - 188s 3ms/sample - loss: 0.1155 - accuracy: 0.9369 - val_loss: 0.1570 - val_accuracy: 0.9272\n",
      "Epoch 11/20\n",
      "64800/64800 [==============================] - 179s 3ms/sample - loss: 0.1051 - accuracy: 0.9397 - val_loss: 0.1471 - val_accuracy: 0.9258\n",
      "Epoch 12/20\n",
      "64800/64800 [==============================] - 180s 3ms/sample - loss: 0.1092 - accuracy: 0.9377 - val_loss: 0.1367 - val_accuracy: 0.9340\n",
      "Epoch 13/20\n",
      "64800/64800 [==============================] - 180s 3ms/sample - loss: 0.1044 - accuracy: 0.9402 - val_loss: 0.1281 - val_accuracy: 0.9268\n",
      "Epoch 14/20\n",
      "64800/64800 [==============================] - 185s 3ms/sample - loss: 0.0992 - accuracy: 0.9416 - val_loss: 0.1302 - val_accuracy: 0.9343\n",
      "Epoch 15/20\n",
      "64800/64800 [==============================] - 171s 3ms/sample - loss: 0.1010 - accuracy: 0.9408 - val_loss: 0.1517 - val_accuracy: 0.9303\n",
      "Epoch 16/20\n",
      "64800/64800 [==============================] - 178s 3ms/sample - loss: 0.1034 - accuracy: 0.9397 - val_loss: 0.1330 - val_accuracy: 0.9300\n",
      "Epoch 17/20\n",
      "64800/64800 [==============================] - 182s 3ms/sample - loss: 0.0936 - accuracy: 0.9432 - val_loss: 0.1392 - val_accuracy: 0.9321\n",
      "Epoch 18/20\n",
      "64800/64800 [==============================] - 179s 3ms/sample - loss: 0.0911 - accuracy: 0.9435 - val_loss: 0.1325 - val_accuracy: 0.9319\n",
      "Epoch 19/20\n",
      "64800/64800 [==============================] - 187s 3ms/sample - loss: 0.0960 - accuracy: 0.9436 - val_loss: 0.1406 - val_accuracy: 0.9301\n",
      "Epoch 20/20\n",
      "64800/64800 [==============================] - 192s 3ms/sample - loss: 0.0911 - accuracy: 0.9444 - val_loss: 0.1283 - val_accuracy: 0.9303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x290a7760b38>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_label,batch_size=120,epochs=20,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = classifier.predict(X_val) \n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928875"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_val,y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X):\n",
    "    embedding_matrix_output = np.zeros((1,l,100))\n",
    "    sent = X.split()\n",
    "    for jx in range(len(sent)):\n",
    "            try:\n",
    "                embedding_matrix_output[0][jx] = embeddings[sent[jx].lower()]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    return embedding_matrix_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45, 100)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=testing('whatever happened it was very bad')\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = classifier.predict(arr) \n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
