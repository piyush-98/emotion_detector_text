{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r'C:\\Users\\PIYUSH\\Downloads\\merged_training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotions\n",
       "27383   i feel awful about it too because it s my job ...  sadness\n",
       "110083                              im alone i feel awful  sadness\n",
       "140764  ive probably mentioned this before but i reall...      joy\n",
       "100071           i was feeling a little low few days back  sadness\n",
       "2837    i beleive that i am much more sensitive to oth...     love"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.iloc[:80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['content', 'sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiments'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making all letters lowercase\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "#Removing Punctuation, Symbols\n",
    "data['content'] = data['content'].str.replace('[^\\w\\s]',' ')\n",
    "#Removing Stop Words using NLTK\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "#Lemmatisation\n",
    "from textblob import Word\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to find the top 10,000 rarest words appearing in the data\n",
    "# freq = pd.Series(' '.join(data['content']).split()).value_counts()[-10000:]\n",
    "# # Removing all those rarely appearing words from the data\n",
    "# freq = list(freq.index)\n",
    "# data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>feel awful job get position succeed happen</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned really feel proud actua...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>feeling little low day back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>beleive much sensitive people feeling tend com...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content sentiments\n",
       "27383          feel awful job get position succeed happen    sadness\n",
       "110083                                im alone feel awful    sadness\n",
       "140764  ive probably mentioned really feel proud actua...        joy\n",
       "100071                        feeling little low day back    sadness\n",
       "2837    beleive much sensitive people feeling tend com...       love"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enthusiasm=happy=fun\n",
    "empty=neutral\n",
    "boredom=sadness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>feel awful job get position succeed happen</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned really feel proud actua...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>feeling little low day back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>beleive much sensitive people feeling tend com...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content sentiments\n",
       "27383          feel awful job get position succeed happen    sadness\n",
       "110083                                im alone feel awful    sadness\n",
       "140764  ive probably mentioned really feel proud actua...        joy\n",
       "100071                        feeling little low day back    sadness\n",
       "2837    beleive much sensitive people feeling tend com...       love"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding output labels 'sadness' as '1' & 'happiness' as '0'\n",
    "from sklearn import preprocessing\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.sentiments.values)\n",
    "# Splitting into training and testing data in 90:10 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, ..., 2, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting TF-IDF parameters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf=X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tfidf=X_val_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tfidf=X_val_tfidf.reshape(X_val_tfidf.shape[0],1,X_val_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf=X_train_tfidf.reshape(X_train_tfidf.shape[0],1,X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 6)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train=to_categorical(y_train)\n",
    "y_val=to_categorical(y_val)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 1, 64)             272640    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 306,054\n",
      "Trainable params: 306,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(LSTM(64,input_shape=(1,1000),return_sequences=True))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(LSTM(64))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(6))\n",
    "classifier.add(Activation('softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64800 samples, validate on 7200 samples\n",
      "Epoch 1/40\n",
      "64800/64800 [==============================] - 16s 247us/sample - loss: 0.7461 - acc: 0.7271 - val_loss: 0.3905 - val_acc: 0.8546\n",
      "Epoch 2/40\n",
      "64800/64800 [==============================] - 13s 193us/sample - loss: 0.4087 - acc: 0.8524 - val_loss: 0.3610 - val_acc: 0.8576\n",
      "Epoch 3/40\n",
      "64800/64800 [==============================] - 13s 193us/sample - loss: 0.3793 - acc: 0.8585 - val_loss: 0.3540 - val_acc: 0.8597\n",
      "Epoch 4/40\n",
      "64800/64800 [==============================] - 13s 194us/sample - loss: 0.3652 - acc: 0.8609 - val_loss: 0.3544 - val_acc: 0.8607\n",
      "Epoch 5/40\n",
      "64800/64800 [==============================] - 13s 196us/sample - loss: 0.3507 - acc: 0.8645 - val_loss: 0.3486 - val_acc: 0.8574\n",
      "Epoch 6/40\n",
      "64800/64800 [==============================] - 12s 193us/sample - loss: 0.3464 - acc: 0.8641 - val_loss: 0.3479 - val_acc: 0.8576\n",
      "Epoch 7/40\n",
      "64800/64800 [==============================] - 13s 195us/sample - loss: 0.3381 - acc: 0.8673 - val_loss: 0.3511 - val_acc: 0.8596\n",
      "Epoch 8/40\n",
      "64800/64800 [==============================] - 13s 195us/sample - loss: 0.3310 - acc: 0.8678 - val_loss: 0.3495 - val_acc: 0.8585\n",
      "Epoch 9/40\n",
      "64800/64800 [==============================] - 13s 196us/sample - loss: 0.3261 - acc: 0.8700 - val_loss: 0.3486 - val_acc: 0.8592\n",
      "Epoch 10/40\n",
      "64800/64800 [==============================] - 13s 196us/sample - loss: 0.3228 - acc: 0.8706 - val_loss: 0.3500 - val_acc: 0.8603\n",
      "Epoch 11/40\n",
      "64800/64800 [==============================] - 13s 194us/sample - loss: 0.3163 - acc: 0.8722 - val_loss: 0.3538 - val_acc: 0.8567\n",
      "Epoch 12/40\n",
      "64800/64800 [==============================] - 13s 198us/sample - loss: 0.3111 - acc: 0.8742 - val_loss: 0.3523 - val_acc: 0.8583\n",
      "Epoch 13/40\n",
      "64800/64800 [==============================] - 13s 198us/sample - loss: 0.3067 - acc: 0.8767 - val_loss: 0.3530 - val_acc: 0.8564\n",
      "Epoch 14/40\n",
      "64800/64800 [==============================] - 13s 204us/sample - loss: 0.3004 - acc: 0.8781 - val_loss: 0.3586 - val_acc: 0.8586\n",
      "Epoch 15/40\n",
      "64800/64800 [==============================] - 13s 201us/sample - loss: 0.2950 - acc: 0.8794 - val_loss: 0.3627 - val_acc: 0.8582\n",
      "Epoch 16/40\n",
      "64800/64800 [==============================] - 13s 202us/sample - loss: 0.2861 - acc: 0.8823 - val_loss: 0.3617 - val_acc: 0.8594\n",
      "Epoch 17/40\n",
      "64800/64800 [==============================] - 13s 203us/sample - loss: 0.2814 - acc: 0.8853 - val_loss: 0.3669 - val_acc: 0.8600\n",
      "Epoch 18/40\n",
      "64800/64800 [==============================] - 13s 203us/sample - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3689 - val_acc: 0.8617\n",
      "Epoch 19/40\n",
      "64800/64800 [==============================] - 13s 206us/sample - loss: 0.2696 - acc: 0.8897 - val_loss: 0.3756 - val_acc: 0.8569\n",
      "Epoch 20/40\n",
      "64800/64800 [==============================] - 13s 201us/sample - loss: 0.2634 - acc: 0.8925 - val_loss: 0.3778 - val_acc: 0.8599\n",
      "Epoch 21/40\n",
      "64800/64800 [==============================] - 13s 203us/sample - loss: 0.2565 - acc: 0.8952 - val_loss: 0.3819 - val_acc: 0.8612\n",
      "Epoch 22/40\n",
      "64800/64800 [==============================] - 13s 206us/sample - loss: 0.2514 - acc: 0.8975 - val_loss: 0.3875 - val_acc: 0.8607\n",
      "Epoch 23/40\n",
      "64800/64800 [==============================] - 13s 206us/sample - loss: 0.2448 - acc: 0.9005 - val_loss: 0.3905 - val_acc: 0.8592\n",
      "Epoch 24/40\n",
      "64800/64800 [==============================] - 13s 205us/sample - loss: 0.2375 - acc: 0.9034 - val_loss: 0.3987 - val_acc: 0.8567\n",
      "Epoch 25/40\n",
      "64800/64800 [==============================] - 13s 207us/sample - loss: 0.2324 - acc: 0.9052 - val_loss: 0.4005 - val_acc: 0.8576\n",
      "Epoch 26/40\n",
      "64800/64800 [==============================] - 14s 211us/sample - loss: 0.2286 - acc: 0.9061 - val_loss: 0.4051 - val_acc: 0.8562\n",
      "Epoch 27/40\n",
      "64800/64800 [==============================] - 14s 210us/sample - loss: 0.2210 - acc: 0.9095 - val_loss: 0.4147 - val_acc: 0.8599\n",
      "Epoch 28/40\n",
      "64800/64800 [==============================] - 14s 211us/sample - loss: 0.2171 - acc: 0.9100 - val_loss: 0.4252 - val_acc: 0.8583\n",
      "Epoch 29/40\n",
      "64800/64800 [==============================] - 14s 211us/sample - loss: 0.2119 - acc: 0.9128 - val_loss: 0.4290 - val_acc: 0.8579\n",
      "Epoch 30/40\n",
      "64800/64800 [==============================] - 14s 210us/sample - loss: 0.2049 - acc: 0.9152 - val_loss: 0.4327 - val_acc: 0.8556\n",
      "Epoch 31/40\n",
      "64800/64800 [==============================] - 13s 208us/sample - loss: 0.2020 - acc: 0.9177 - val_loss: 0.4419 - val_acc: 0.8569\n",
      "Epoch 32/40\n",
      "64800/64800 [==============================] - 14s 211us/sample - loss: 0.1974 - acc: 0.9200 - val_loss: 0.4473 - val_acc: 0.8560\n",
      "Epoch 33/40\n",
      "64800/64800 [==============================] - 14s 208us/sample - loss: 0.1925 - acc: 0.9216 - val_loss: 0.4478 - val_acc: 0.8581\n",
      "Epoch 34/40\n",
      "64800/64800 [==============================] - 14s 209us/sample - loss: 0.1910 - acc: 0.9215 - val_loss: 0.4605 - val_acc: 0.8596\n",
      "Epoch 35/40\n",
      "64800/64800 [==============================] - 14s 209us/sample - loss: 0.1859 - acc: 0.9243 - val_loss: 0.4665 - val_acc: 0.8560\n",
      "Epoch 36/40\n",
      "64800/64800 [==============================] - 14s 211us/sample - loss: 0.1817 - acc: 0.9237 - val_loss: 0.4770 - val_acc: 0.8550\n",
      "Epoch 37/40\n",
      "64800/64800 [==============================] - 14s 212us/sample - loss: 0.1780 - acc: 0.9265 - val_loss: 0.4808 - val_acc: 0.8576\n",
      "Epoch 38/40\n",
      "64800/64800 [==============================] - 14s 211us/sample - loss: 0.1776 - acc: 0.9266 - val_loss: 0.4833 - val_acc: 0.8578\n",
      "Epoch 39/40\n",
      "64800/64800 [==============================] - 14s 212us/sample - loss: 0.1722 - acc: 0.9293 - val_loss: 0.4923 - val_acc: 0.8569\n",
      "Epoch 40/40\n",
      "64800/64800 [==============================] - 14s 213us/sample - loss: 0.1716 - acc: 0.9299 - val_loss: 0.4990 - val_acc: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16a99791940>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "classifier.fit(X_train_tfidf,y_train,batch_size=32,epochs=40,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = classifier.predict(X_val_tfidf) \n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y_val.argmax(axis=-1)\n",
    "y_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
